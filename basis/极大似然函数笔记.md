# 极大似然函数笔记

## 1. 似然与概率的区别

	1. 有一枚均匀的硬币，我们来求它抛20次有12次正面的可能性。这里的可能性指的就是概率。从机器学习的角度来说，概率指的是一个模型(硬币)出现某种结果(12次正8次反)的可能性。
 	2. 有一枚硬币抛出20次，结果有12次正面8次反面，我们来求这枚硬币是否均匀的可能性。这里的可能性指的就是似然。从机器学习的角度来说，似然指的是模型的参数(是否均匀)对产生这个结果(12次正8次反)的可能性。

## 2. 构造似然函数

​	假设有一个总体分布X，它的参数为θ(计算总体分布X中的每一个值出现的概率都会用到它)。
​	现在从总体分布X中随机取n个数据作为一个样本x(x1，x2，x3…xn)。也就是说这个样本有n个特征，每个特征的取值都服从总体分布X。
​	P(x;θ)表示给定参数θ时，从总体分布X中取得这个样本x的可能性。

**现在我们来求这个可能性P(x;θ)**：

![20181117165250256](.\极大似然\20181117165250256.png)

1. **第一种情况**：从总体分布 X 中随机取两个样本 x1 和 x2，如果 P(x1 ; \theta )  > P(x2 ; \theta)，那么就认为从总体分布 X 中取得 x1 样本的可能性比较大。如果把总体分布 X 看作 n 维的样本空间，那么 x1 和 x2 就是其中的两个 n 维的点，则 P(x1 ; \theta ) > P(x2 ; \theta ) 就是表示从样本空间中取得 x1 这个点的可能性比较大。这里的 P(x1 ; \theta ) 和 P(x2 ; \theta ) 就是概率。
2. **第二种情况**：从总体分布 X 中随机取一个样本 x1， 总体分布 X 的参数 \theta 现在给定两个值 \theta1 和 \theta2 。如果 P(x1 ; \theta1 ) > P(x1 ; \theta2 ) ，那么就认为参数 \theta1 对产生样本 x1 的似然性（可能性）要更大。这里 P(x1; \theta1) 和 P(x1; \theta2) 就是似然，P(X ; \theta ) 作为参数 \theta 产生样本 X 的似然性的一种度量。

**研究极大似然函数就是研究第二种情况**：

​	P(X ; \theta ) 作为参数 \theta 产生样本 X 的似然性的一种度量。那么我们给定样本 X 来求 P(X ; \theta ) ，这时得到一个只剩 \theta 的式子，将这个式子称为 \theta 的似然函数，记为 L(\theta; X) 。使得 L(\theta; X) 取最大值的那个 \theta^ ，我们就认为它是总体分布 X 的参数 \theta 的一个比较可靠的估计值。因为那个参数 \theta^ 使得总体分布 X 取得样本 X 的可能性最大，所以总体分布 X 的参数 \theta 就可以取值为 \theta^。

给定样本 X (x1, x2, x3, .... , xn)，构建 \theta 的似然函数 L(\theta; x) 如下：

![20181117173023655](E:\电子书\小象AI班\NLP-Self-learning-Knowledge\basis\极大似然\20181117173023655.png)